{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swb58FXinjML",
        "outputId": "4ca0f4ee-12c8-496c-983d-a10042292bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/cop')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pickle5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnHn7C7kVeaF",
        "outputId": "aa20f825-3d39-4af2-b85b-d4e3c97f4b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.8/dist-packages (0.0.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DYGtH-XMsfG"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
        "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmj-zvTENr9i"
      },
      "outputs": [],
      "source": [
        "with open(\"indifinal.pickle\",\"rb\") as fr:\n",
        "    indimath = pickle.load(fr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indimath"
      ],
      "metadata": {
        "id": "2GsFzF3JadkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "2ede3d65-15b7-4570-d96b-49c0e8ec2110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date                               title  \\\n",
              "0        22.09.30        (동아출판 안병곤) 2단원 나눗셈 평가 자료입니다!   \n",
              "1        22.09.30    2학기 2단원 나눗셈 카카오프렌즈(졸린곰선생님) 6-8차시   \n",
              "2        22.09.30  [수학문어이야기] 3-2-2. 나눗셈 (7차시) (동아안병곤)   \n",
              "3        22.09.29             [동아 안병곤] 곱셈 단원평가 자료입니다.   \n",
              "4        22.09.29               [천재 한대희]3-2-4 분수 도입게임   \n",
              "...           ...                                 ...   \n",
              "29483  2016-08-05                제주대 시무식 강의평가 우수교수 등    \n",
              "29484  2014-12-27                제주대 강의평가 우수교수 등 시상 제   \n",
              "29485  2013-01-06                인재개발관에 가면 공부도 하고 중국어   \n",
              "29486  2014-04-03                원광대학교 교원 보직 인사 대학원장    \n",
              "29487  2015-09-16                신용섭 사장 콘텐츠 경쟁력 강화 신용   \n",
              "\n",
              "                                                 content  \\\n",
              "0      2단원 나눗셈 단원 평가 자료입니다!\\n단원평가부터 단원 시작 전 진단평가, 서술형...   \n",
              "1                졸린곰 선생님 자료를 천재 교과서에 맞게 변경하였습니다~\\n감사합니다.   \n",
              "2      -\\n태그되어 있는 제 이름을 클릭하시면 제가 수학에서 올린자료를 한번에 보실 수 ...   \n",
              "3      곱셈 단원 평가 자료입니다. 조금 늦은 듯 하지만 보충 지도를 위해 활용하시면 좋을...   \n",
              "4      3-2-4 분수 단원도입 빙고게임입니다. 3-1-6 분수 복습 게임입니다.\\n지도서...   \n",
              "...                                                  ...   \n",
              "29483                               제주대 시무식 강의평가 우수교수 등    \n",
              "29484                               제주대 강의평가 우수교수 등 시상 제   \n",
              "29485                               인재개발관에 가면 공부도 하고 중국어   \n",
              "29486                               원광대학교 교원 보직 인사 대학원장    \n",
              "29487                               신용섭 사장 콘텐츠 경쟁력 강화 신용   \n",
              "\n",
              "                                                   files  Grade  \\\n",
              "0      첨부파일 4\\n모두 받기\\n(3-2-2)단원 평가.zip\\n·899KB\\n(3-2-...      3   \n",
              "1      첨부파일 3\\n모두 받기\\n2단원 6차시.pptx\\n·42MB\\n2단원 7차시.pp...      3   \n",
              "2      첨부파일 1\\n동아안 3-2-2-(7) 나머지가 있는 나눗셈을 할 수 있어요(2)_...      3   \n",
              "3                         첨부파일 1\\n(3-2-1)단원 평가.zip\\n·2MB      3   \n",
              "4      첨부파일 2\\n모두 받기\\n(3-2-4)단원도입 분수 빙고게임.pptx\\n·13MB...      3   \n",
              "...                                                  ...    ...   \n",
              "29483  첨부파일 3\\n모두 받기\\n구글트렌드 활용해 자료 분석하기.hwp\\n·23KB\\n빅...      5   \n",
              "29484  첨부파일 2\\n모두 받기\\n5차시_미세먼지 농도 그래프 그리기.hwp\\n·18KB\\...      5   \n",
              "29485  첨부파일 3\\n모두 받기\\n6-8.pptx\\n·9MB\\n6-8 동기유발.mp4\\n·...      5   \n",
              "29486                      첨부파일 1\\n꺾은선그래프 4차시.show\\n·3MB      5   \n",
              "29487                    첨부파일 1\\n사각형 스폰지밥 퀴즈.pptx\\n·18MB      5   \n",
              "\n",
              "                                                    text  numreply  numlikes  \\\n",
              "0      동아출판 안병곤 2단원 나눗셈 평가 자료입니다 2단원 나눗셈 단원 평가 자료입니다단...       0.0      16.0   \n",
              "1      2학기 2단원 나눗셈 카카오 프렌즈 졸린 곰 선생님 68차시 졸린 곰 선생님 자료를...       0.0      12.0   \n",
              "2      수학 문어 이야기 322 나눗셈 7차시 동아안병곤 태그 되어 있는 제 이름을 클릭하...       0.0       4.0   \n",
              "3      동아 안병곤 곱셈 단원평가 자료입니다 곱셈 단원 평가 자료입니다 조금 늦은 듯하지만...       0.0       4.0   \n",
              "4      천재 한대희 324 분수 도입 게임 324 분수 단원도 입 빙고게임입니다 316 분...       1.0      22.0   \n",
              "...                                                  ...       ...       ...   \n",
              "29483  제주대 시무식 강의평가 우수 교수 등 시상 제주대학교는 지난 2일 아라뮤즈홀에서 시...       3.0      54.0   \n",
              "29484  제주대 강의평가 우수 교수 등 시상 제주대학교는 지난 2일 아라뮤즈홀에서 시무식을 ...       3.0      54.0   \n",
              "29485  인재 개발관에 가면 공부도 하고 중국어도 배운다 완주군이 지역 인재 육성을 위해 고...       1.0      18.0   \n",
              "29486  원광대학교 교원 보직 인사 대학원장 정진철 환경조경학과 교수교육대학원장 김용섭 수학...       7.0     126.0   \n",
              "29487  신용섭 사장 콘텐츠 경쟁력 강화 신용섭  사장은 2일 신년사를 통해 콘텐츠 경쟁력 ...       8.0     144.0   \n",
              "\n",
              "                                               tokenized  \\\n",
              "0      [동아, 출판, 안병곤, 나눗셈, 평가, 자료, 나눗셈, 평가, 자료, 평가, 시작...   \n",
              "1                   [나눗셈, 카카오, 프렌즈, 자료, 천재, 교과서, 변경, 다감]   \n",
              "2      [문어, 이야기, 나눗셈, 동아, 안병곤, 태그, 이름, 클릭, 자료, 그림, 캐릭...   \n",
              "3      [동아, 안병곤, 곱셈, 평가, 자료, 곱셈, 평가, 자료, 보충, 지도, 활용, ...   \n",
              "4      [천재, 대희, 분수, 도입, 게임, 분수, 빙고게임, 분수, 복습, 게임, 지도서...   \n",
              "...                                                  ...   \n",
              "29483  [제주, 시무, 강의, 평가, 우수, 교수, 시상, 제주대학교, 지난, 뮤즈, 무식...   \n",
              "29484  [제주, 강의, 평가, 우수, 교수, 시상, 제주대학교, 지난, 뮤즈, 무식, 실시...   \n",
              "29485  [인재, 개발, 가면, 공부, 중국어, 완주군, 지역, 인재, 육성, 고산면, 완공...   \n",
              "29486  [원광, 대학교, 교원, 보직, 인사, 대학원, 정진철, 경조, 경학, 교수, 교육...   \n",
              "29487  [신용섭, 사장, 콘텐츠, 경쟁력, 강화, 신용섭, 사장, 신년사, 콘텐츠, 경쟁력...   \n",
              "\n",
              "                                              list_token  reply_category  \n",
              "0      동아,출판,안병곤,나눗셈,평가,자료,나눗셈,평가,자료,평가,시작,진단,평가,서술,평...             0.0  \n",
              "1                            나눗셈,카카오,프렌즈,자료,천재,교과서,변경,다감             0.0  \n",
              "2      문어,이야기,나눗셈,동아,안병곤,태그,이름,클릭,자료,그림,캐릭터,모든,자료,그린,...             0.0  \n",
              "3            동아,안병곤,곱셈,평가,자료,곱셈,평가,자료,보충,지도,활용,클래스,자료,출처             0.0  \n",
              "4      천재,대희,분수,도입,게임,분수,빙고게임,분수,복습,게임,지도서,게임,응용,화면,도...             1.0  \n",
              "...                                                  ...             ...  \n",
              "29483  제주,시무,강의,평가,우수,교수,시상,제주대학교,지난,뮤즈,무식,실시,향진,총장,신...             1.0  \n",
              "29484  제주,강의,평가,우수,교수,시상,제주대학교,지난,뮤즈,무식,실시,향진,총장,신년사,...             1.0  \n",
              "29485  인재,개발,가면,공부,중국어,완주군,지역,인재,육성,고산면,완공,인재,개발,인재,스...             1.0  \n",
              "29486  원광,대학교,교원,보직,인사,대학원,정진철,경조,경학,교수,교육대학,원장,김용섭,교...             0.0  \n",
              "29487  신용섭,사장,콘텐츠,경쟁력,강화,신용섭,사장,신년사,콘텐츠,경쟁력,강화,시청자,프로...             0.0  \n",
              "\n",
              "[29488 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19c771fe-2f01-44cd-819b-9a1ddf7d0055\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>files</th>\n",
              "      <th>Grade</th>\n",
              "      <th>text</th>\n",
              "      <th>numreply</th>\n",
              "      <th>numlikes</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>list_token</th>\n",
              "      <th>reply_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.09.30</td>\n",
              "      <td>(동아출판 안병곤) 2단원 나눗셈 평가 자료입니다!</td>\n",
              "      <td>2단원 나눗셈 단원 평가 자료입니다!\\n단원평가부터 단원 시작 전 진단평가, 서술형...</td>\n",
              "      <td>첨부파일 4\\n모두 받기\\n(3-2-2)단원 평가.zip\\n·899KB\\n(3-2-...</td>\n",
              "      <td>3</td>\n",
              "      <td>동아출판 안병곤 2단원 나눗셈 평가 자료입니다 2단원 나눗셈 단원 평가 자료입니다단...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>[동아, 출판, 안병곤, 나눗셈, 평가, 자료, 나눗셈, 평가, 자료, 평가, 시작...</td>\n",
              "      <td>동아,출판,안병곤,나눗셈,평가,자료,나눗셈,평가,자료,평가,시작,진단,평가,서술,평...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.09.30</td>\n",
              "      <td>2학기 2단원 나눗셈 카카오프렌즈(졸린곰선생님) 6-8차시</td>\n",
              "      <td>졸린곰 선생님 자료를 천재 교과서에 맞게 변경하였습니다~\\n감사합니다.</td>\n",
              "      <td>첨부파일 3\\n모두 받기\\n2단원 6차시.pptx\\n·42MB\\n2단원 7차시.pp...</td>\n",
              "      <td>3</td>\n",
              "      <td>2학기 2단원 나눗셈 카카오 프렌즈 졸린 곰 선생님 68차시 졸린 곰 선생님 자료를...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>[나눗셈, 카카오, 프렌즈, 자료, 천재, 교과서, 변경, 다감]</td>\n",
              "      <td>나눗셈,카카오,프렌즈,자료,천재,교과서,변경,다감</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.09.30</td>\n",
              "      <td>[수학문어이야기] 3-2-2. 나눗셈 (7차시) (동아안병곤)</td>\n",
              "      <td>-\\n태그되어 있는 제 이름을 클릭하시면 제가 수학에서 올린자료를 한번에 보실 수 ...</td>\n",
              "      <td>첨부파일 1\\n동아안 3-2-2-(7) 나머지가 있는 나눗셈을 할 수 있어요(2)_...</td>\n",
              "      <td>3</td>\n",
              "      <td>수학 문어 이야기 322 나눗셈 7차시 동아안병곤 태그 되어 있는 제 이름을 클릭하...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[문어, 이야기, 나눗셈, 동아, 안병곤, 태그, 이름, 클릭, 자료, 그림, 캐릭...</td>\n",
              "      <td>문어,이야기,나눗셈,동아,안병곤,태그,이름,클릭,자료,그림,캐릭터,모든,자료,그린,...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.09.29</td>\n",
              "      <td>[동아 안병곤] 곱셈 단원평가 자료입니다.</td>\n",
              "      <td>곱셈 단원 평가 자료입니다. 조금 늦은 듯 하지만 보충 지도를 위해 활용하시면 좋을...</td>\n",
              "      <td>첨부파일 1\\n(3-2-1)단원 평가.zip\\n·2MB</td>\n",
              "      <td>3</td>\n",
              "      <td>동아 안병곤 곱셈 단원평가 자료입니다 곱셈 단원 평가 자료입니다 조금 늦은 듯하지만...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[동아, 안병곤, 곱셈, 평가, 자료, 곱셈, 평가, 자료, 보충, 지도, 활용, ...</td>\n",
              "      <td>동아,안병곤,곱셈,평가,자료,곱셈,평가,자료,보충,지도,활용,클래스,자료,출처</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.09.29</td>\n",
              "      <td>[천재 한대희]3-2-4 분수 도입게임</td>\n",
              "      <td>3-2-4 분수 단원도입 빙고게임입니다. 3-1-6 분수 복습 게임입니다.\\n지도서...</td>\n",
              "      <td>첨부파일 2\\n모두 받기\\n(3-2-4)단원도입 분수 빙고게임.pptx\\n·13MB...</td>\n",
              "      <td>3</td>\n",
              "      <td>천재 한대희 324 분수 도입 게임 324 분수 단원도 입 빙고게임입니다 316 분...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>[천재, 대희, 분수, 도입, 게임, 분수, 빙고게임, 분수, 복습, 게임, 지도서...</td>\n",
              "      <td>천재,대희,분수,도입,게임,분수,빙고게임,분수,복습,게임,지도서,게임,응용,화면,도...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29483</th>\n",
              "      <td>2016-08-05</td>\n",
              "      <td>제주대 시무식 강의평가 우수교수 등</td>\n",
              "      <td>제주대 시무식 강의평가 우수교수 등</td>\n",
              "      <td>첨부파일 3\\n모두 받기\\n구글트렌드 활용해 자료 분석하기.hwp\\n·23KB\\n빅...</td>\n",
              "      <td>5</td>\n",
              "      <td>제주대 시무식 강의평가 우수 교수 등 시상 제주대학교는 지난 2일 아라뮤즈홀에서 시...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>[제주, 시무, 강의, 평가, 우수, 교수, 시상, 제주대학교, 지난, 뮤즈, 무식...</td>\n",
              "      <td>제주,시무,강의,평가,우수,교수,시상,제주대학교,지난,뮤즈,무식,실시,향진,총장,신...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29484</th>\n",
              "      <td>2014-12-27</td>\n",
              "      <td>제주대 강의평가 우수교수 등 시상 제</td>\n",
              "      <td>제주대 강의평가 우수교수 등 시상 제</td>\n",
              "      <td>첨부파일 2\\n모두 받기\\n5차시_미세먼지 농도 그래프 그리기.hwp\\n·18KB\\...</td>\n",
              "      <td>5</td>\n",
              "      <td>제주대 강의평가 우수 교수 등 시상 제주대학교는 지난 2일 아라뮤즈홀에서 시무식을 ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>[제주, 강의, 평가, 우수, 교수, 시상, 제주대학교, 지난, 뮤즈, 무식, 실시...</td>\n",
              "      <td>제주,강의,평가,우수,교수,시상,제주대학교,지난,뮤즈,무식,실시,향진,총장,신년사,...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29485</th>\n",
              "      <td>2013-01-06</td>\n",
              "      <td>인재개발관에 가면 공부도 하고 중국어</td>\n",
              "      <td>인재개발관에 가면 공부도 하고 중국어</td>\n",
              "      <td>첨부파일 3\\n모두 받기\\n6-8.pptx\\n·9MB\\n6-8 동기유발.mp4\\n·...</td>\n",
              "      <td>5</td>\n",
              "      <td>인재 개발관에 가면 공부도 하고 중국어도 배운다 완주군이 지역 인재 육성을 위해 고...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>[인재, 개발, 가면, 공부, 중국어, 완주군, 지역, 인재, 육성, 고산면, 완공...</td>\n",
              "      <td>인재,개발,가면,공부,중국어,완주군,지역,인재,육성,고산면,완공,인재,개발,인재,스...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29486</th>\n",
              "      <td>2014-04-03</td>\n",
              "      <td>원광대학교 교원 보직 인사 대학원장</td>\n",
              "      <td>원광대학교 교원 보직 인사 대학원장</td>\n",
              "      <td>첨부파일 1\\n꺾은선그래프 4차시.show\\n·3MB</td>\n",
              "      <td>5</td>\n",
              "      <td>원광대학교 교원 보직 인사 대학원장 정진철 환경조경학과 교수교육대학원장 김용섭 수학...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>[원광, 대학교, 교원, 보직, 인사, 대학원, 정진철, 경조, 경학, 교수, 교육...</td>\n",
              "      <td>원광,대학교,교원,보직,인사,대학원,정진철,경조,경학,교수,교육대학,원장,김용섭,교...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29487</th>\n",
              "      <td>2015-09-16</td>\n",
              "      <td>신용섭 사장 콘텐츠 경쟁력 강화 신용</td>\n",
              "      <td>신용섭 사장 콘텐츠 경쟁력 강화 신용</td>\n",
              "      <td>첨부파일 1\\n사각형 스폰지밥 퀴즈.pptx\\n·18MB</td>\n",
              "      <td>5</td>\n",
              "      <td>신용섭 사장 콘텐츠 경쟁력 강화 신용섭  사장은 2일 신년사를 통해 콘텐츠 경쟁력 ...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>[신용섭, 사장, 콘텐츠, 경쟁력, 강화, 신용섭, 사장, 신년사, 콘텐츠, 경쟁력...</td>\n",
              "      <td>신용섭,사장,콘텐츠,경쟁력,강화,신용섭,사장,신년사,콘텐츠,경쟁력,강화,시청자,프로...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29488 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19c771fe-2f01-44cd-819b-9a1ddf7d0055')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19c771fe-2f01-44cd-819b-9a1ddf7d0055 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19c771fe-2f01-44cd-819b-9a1ddf7d0055');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKpea0Ggst00"
      },
      "outputs": [],
      "source": [
        "x = indimath['tokenized']\n",
        "y = indimath['reply_category']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAJt4VbqNcx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a3babd-ea70-4d18-e5b7-a996b5907eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-1e0f240cc592>:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  words = model.wv.syn0\n",
            "<ipython-input-15-1e0f240cc592>:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  X_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-1e0f240cc592>:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  X_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n"
          ]
        }
      ],
      "source": [
        "model = gensim.models.Word2Vec(x, min_count= 10, size = 300, window= 4, sg= 1)\n",
        "\n",
        "words = model.wv.syn0\n",
        "print(len(words))\n",
        "\n",
        "X_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train])\n",
        "X_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test])\n",
        "\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(300, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(300, dtype=float))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier \n",
        "rf_clf = RandomForestClassifier(random_state=11, max_depth= 10, min_samples_leaf=3, min_samples_split=2)\n",
        "lr_clf = LogisticRegression(C= 1000.0)\n",
        "svm_clf =SVC(kernel = 'rbf', probability=True)\n",
        "ridge_clf = RidgeClassifier()\n",
        "\n",
        "\n",
        "# RandomForestClassifier \n",
        "rf_clf.fit(X_train_vect_avg , y_train)\n",
        "rf_pred = rf_clf.predict(X_test_vect_avg)\n",
        "print('#Random Forest train set score: {:.3f}'.format(rf_clf.score(X_train_vect_avg, y_train)))\n",
        "print('#Random Forest test set score: {:.3f}'.format(rf_clf.score(X_test_vect_avg, y_test)))\n",
        "print('#Random Forest accuracy:{0:.3f}'.format(accuracy_score(y_test, rf_pred)))\n",
        "print('#Random Forest f1 : {0:.3f}'.format(f1_score(y_test , rf_pred)))\n",
        "print( '-------------------------------------- ')\n",
        "\n",
        "\n",
        "# LogisticRegression\n",
        "lr_clf.fit(X_train_vect_avg , y_train)\n",
        "lr_pred = lr_clf.predict(X_test_vect_avg)\n",
        "print('#Logistic Regression train set score: {:.3f}'.format(lr_clf.score(X_train_vect_avg, y_train)))\n",
        "print('#Logistic Regression test set score: {:.3f}'.format(lr_clf.score(X_test_vect_avg, y_test)))\n",
        "print('#Logistic Regression accuracy: {0:.3f}'.format(accuracy_score(y_test, lr_pred)))\n",
        "print('#Logistic Regression f1 : {0:.3f}'.format(f1_score(y_test , lr_pred)))\n",
        "print( '-------------------------------------- ')\n",
        "\n",
        "\n",
        "# support vector machine\n",
        "svm_clf.fit(X_train_vect_avg , y_train)\n",
        "svm_pred = svm_clf.predict(X_test_vect_avg)\n",
        "print('#SVM Regression train set score: {:.3f}'.format(svm_clf.score(X_train_vect_avg, y_train)))\n",
        "print('#SVM Regression test set score: {:.3f}'.format(svm_clf.score(X_test_vect_avg, y_test)))\n",
        "print('#SVM Regression accuracy: {0:.3f}'.format(accuracy_score(y_test, svm_pred)))\n",
        "print('#SVM Regression f1 : {0:.3f}'.format(f1_score(y_test , svm_pred)))\n",
        "print( '-------------------------------------- ')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3z-VMzLLvb",
        "outputId": "adc42f51-dbbf-466c-d0a3-4a07750bfea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Random Forest train set score: 0.659\n",
            "#Random Forest test set score: 0.681\n",
            "#Random Forest accuracy:0.681\n",
            "#Random Forest f1 : 0.699\n",
            "-------------------------------------- \n",
            "#Logistic Regression train set score:0.659\n",
            "#Logistic Regression test set score: 0.681\n",
            "#Logistic Regression accuracy: 0.681\n",
            "#Logistic Regression f1 :0.699\n",
            "-------------------------------------- \n",
            "#SVM Regression train set score: 0.674\n",
            "#SVM Regression test set score:0.704\n",
            "#SVM Regression accuracy: 0.704\n",
            "#SVM Regression f1 : 0.720\n",
            "-------------------------------------- \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_clf.fit(X_train_vect_avg, y_train) \n",
        "ridge_pred = ridge_clf.predict(X_test_vect_avg)\n",
        "\n",
        "print('#Ridge Regression train set score: {:.3f}'.format(ridge_clf.score(X_train_vect_avg, y_train)))\n",
        "print('#Ridge Regression test set score: {:.3f}'.format(ridge_clf.score(X_test_vect_avg, y_test)))\n",
        "print('#Ridge Regression accuracy: {0:.4f}'.format(accuracy_score(y_test, ridge_pred)))\n",
        "print('#Ridge Regression f1 : {0:.3f}'.format(f1_score(y_test , ridge_pred)))\n",
        "print( '-------------------------------------- ')\n"
      ],
      "metadata": {
        "id": "mvytFZk-tPNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66739743-0f57-4224-da91-7fc6a336a595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Ridge Regression train set score: 0.674\n",
            "#Ridge Regression test set score: 0.684\n",
            "#Ridge Regression accuracy: 0.6841\n",
            "#Ridge Regression f1 : 0.710\n",
            "-------------------------------------- \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr_clf = LogisticRegression()\n",
        "svm_clf =SVC(kernel = 'rbf', probability=True)\n",
        "ridge_clf = RidgeClassifier()\n",
        "\n",
        "\n",
        "print( '------------------ Logistic -------------------- ')\n",
        "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
        "\n",
        "f1 = make_scorer(f1_score , average='macro')\n",
        "\n",
        "grid_lrclf = GridSearchCV(lr_clf , grid , scoring=f1 , cv=5)\n",
        "grid_lrclf.fit(X_train_vect_avg , y_train)\n",
        "\n",
        "print('GridSearchCV best parameter in Logistic :',grid_lrclf.best_params_)\n",
        "print('GridSearchCV best f1 score : {0:.4f}'.format(grid_lrclf.best_score_))\n",
        "best_lfclf = grid_lrclf.best_estimator_\n",
        "dpredictions = best_lfclf.predict(X_test_vect_avg)\n",
        "f1 = f1_score(y_test , dpredictions)\n",
        "print('test Logistic t f1 : {0:.4f}'.format(f1))\n",
        "print( '----------------------------------------- ')\n",
        "\n",
        "\n",
        "\n",
        "print( '------------------ Ridge -------------------- ')\n",
        "parameters = {'alpha': [1,0.1,0.01,0.001,0.0001,0]}\n",
        "\n",
        "f1 = make_scorer(f1_score , average='macro')\n",
        "\n",
        "grid_ridclf = GridSearchCV(ridge_clf , grid , scoring=f1 , cv=5)\n",
        "grid_ridclf.fit(X_train_vect_avg , y_train)\n",
        "\n",
        "print('GridSearchCV best parameter in Ridge :',grid_ridclf.best_params_)\n",
        "print('GridSearchCV best f1 score : {0:.4f}'.format(grid_ridclf.best_score_))\n",
        "best_ridfclf = grid_ridclf.best_estimator_\n",
        "dpredictions = best_ridfclf.predict(X_test_vect_avg)\n",
        "f1 = f1_score(y_test , dpredictions)\n",
        "print('test Ridge f1 : {0:.4f}'.format(f1))\n",
        "print( '-------------------------------------- ')\n",
        "\n",
        "\n",
        "\n",
        "print( '------------------ svm -------------------- ')\n",
        "f1 = make_scorer(f1_score , average='macro')\n",
        "\n",
        "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "             'gamma': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
        "\n",
        "grid_svmclf = GridSearchCV(svm_clf , param_grid=parameters , scoring=f1 , cv=5)\n",
        "grid_svmclf.fit(X_train_vect_avg , y_train)\n",
        "\n",
        "print('GridSearchCV best parameter in svm :',grid_svmclf.best_params_)\n",
        "print('GridSearchCV best f1 score : {0:.4f}'.format(grid_svmclf.best_score_))\n",
        "best_svmclf = grid_svmclf.best_estimator_\n",
        "dpredictions = best_svmclf.predict(X_test_vect_avg)\n",
        "f1 = f1_score(y_test , dpredictions)\n",
        "print('test svm f1 : {0:.4f}'.format(f1))\n",
        "print( '-------------------------------------- ')\n"
      ],
      "metadata": {
        "id": "l2etho4wOnRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247bd767-6ffa-4c2b-bd06-e0885506bf51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ Logistic -------------------- \n",
            "GridSearchCV best parameter in Logistic : {'C': 0.001, 'penalty': 'l2'}\n",
            "GridSearchCV best f1 score : {0:.4f} : 0.7204\n",
            "test Logistic t f1 : 0.7107\n",
            "----------------------------------------- \n",
            "------------------ Ridge -------------------- \n",
            "GridSearchCV best parameter in Ridge : {'alpha': 1 }\n",
            "GridSearchCV best f1 score : 0.7204\n",
            "test Ridge f1 : 0.7163\n",
            "-------------------------------------- \n",
            "------------------ svm -------------------- \n",
            "GridSearchCV best parameter in svm : {'C' : 10, 'gamma': 0.01}\n",
            "GridSearchCV best f1 score : 0.7631\n",
            "test svm f1 : 0.7520\n",
            "-------------------------------------- \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kobert embedding and classification"
      ],
      "metadata": {
        "id": "N32nA51Ht0IG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuM8uzL5OzQh"
      },
      "outputs": [],
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3 \n",
        "!pip install torch\n",
        "\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7BHrTtNO3hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a052ffb-f2db-4cd6-d729-a37dbba1414e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/Colab Notebooks/cop/.cache/kobert_v1.zip\n",
            "using cached model. /content/gdrive/MyDrive/Colab Notebooks/cop/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gpZC-T7oIEa",
        "outputId": "7c041f06-e417-4ba5-86c8-9b3e24da3cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/Colab Notebooks/cop/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2yMSxioqos7"
      },
      "outputs": [],
      "source": [
        "indimath['reply_category']= indimath['reply_category'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCECxDurr7Lh"
      },
      "outputs": [],
      "source": [
        "data_list = []\n",
        "for q, label in zip(indimath['text'], indimath['reply_category'])  :\n",
        "    data = []\n",
        "    data.append(q)\n",
        "    data.append(str(label))\n",
        "\n",
        "    data_list.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgPBbUVzo9IX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=34)\n",
        "dataset_train, dataset_val = train_test_split(dataset_train, test_size=0.2, shuffle=True, random_state=34)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Meh_NxmPrYBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fc1c80-2714-4564-bcaf-188605b41b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "data_test = BERTDataset(data_list, 0, 1, tok, max_len, True, False)\n",
        "dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrweSbFqoQjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a4310c-f49b-4211-ab8e-09a75e6457c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_val = BERTDataset(dataset_val, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "val_dataloader = torch.utils.data.DataLoader(data_val, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9IqP9YcJBDx",
        "outputId": "50caf714-7e14-4c9a-f546-31d5aff0f79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.BERTDataset at 0x7efc2db70be0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAVYBsxgoUbb"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=2,  # change class size {'0','1','2','3'}\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate            \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW8H1aYHVqcZ"
      },
      "outputs": [],
      "source": [
        "## Setting parameters\n",
        "max_len = 512\n",
        "batch_size = 16\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 3\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag4o8nyVoXAq"
      },
      "outputs": [],
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
        "\n",
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QavlIpLgoZli"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQaJ-nnhtfvT"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wGC33cJt58R",
        "outputId": "fab10fbd-9b82-4136-ddfe-3b999f5109d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:01<40:54,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 0.4873751997947693 train acc 0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:30<26:43,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 201 loss 0.4823119640350342 train acc 0.753731343283582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:59<24:19,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 401 loss 0.6490050554275513 train acc 0.7459476309226932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:27<21:42,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 601 loss 0.598297119140625 train acc 0.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:56<19:22,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 801 loss 0.47646158933639526 train acc 0.7496878901373284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [12:25<16:47,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1001 loss 0.15621842443943024 train acc 0.7532467532467533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:53<14:21,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1201 loss 0.34113070368766785 train acc 0.7526019983347211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [17:22<11:50,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1401 loss 0.19426074624061584 train acc 0.7540149892933619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:51<09:21,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1601 loss 0.5658798217773438 train acc 0.7532792004996877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [22:19<06:54,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1801 loss 0.47296831011772156 train acc 0.7552054414214325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [24:48<04:27,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 2001 loss 0.24522872269153595 train acc 0.757808595702149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [27:17<01:57,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 2201 loss 0.5527897477149963 train acc 0.7564743298500681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [29:14<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 train acc 0.7563056379821959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:30<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val acc 0.7386299435028248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [03:07<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.7562669376693767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:01<41:01,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.4757758378982544 train acc 0.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:29<26:46,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 201 loss 0.40804365277290344 train acc 0.7580845771144279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:58<24:16,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 401 loss 0.6064369678497314 train acc 0.7528054862842892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:27<21:45,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 601 loss 0.7139410376548767 train acc 0.7589434276206323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:56<19:23,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 801 loss 0.5388011932373047 train acc 0.7596754057428214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [12:25<16:46,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1001 loss 0.23129433393478394 train acc 0.761988011988012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:53<14:22,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1201 loss 0.31855180859565735 train acc 0.7620732722731057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [17:22<11:51,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1401 loss 0.21736685931682587 train acc 0.7624018558172734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:51<09:23,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1601 loss 0.4524751901626587 train acc 0.764053716427233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [22:19<06:54,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1801 loss 0.4814135432243347 train acc 0.7649916712937257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [24:48<04:26,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 2001 loss 0.24967841804027557 train acc 0.7680534732633684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [27:17<01:57,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 2201 loss 0.780627965927124 train acc 0.7677760109041345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [29:15<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 train acc 0.7676451886392539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:30<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val acc 0.7589689265536723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [03:08<00:00,  3.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.7704945799457995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:00<39:13,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.359561026096344 train acc 0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:29<26:43,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 201 loss 0.5850202441215515 train acc 0.7686567164179104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:58<24:09,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 401 loss 0.16233375668525696 train acc 0.7674563591022444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:28<21:45,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 601 loss 0.8145666718482971 train acc 0.7687188019966722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:56<19:26,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 801 loss 0.3718448877334595 train acc 0.7702871410736579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [12:26<16:47,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1001 loss 0.22965560853481293 train acc 0.7736013986013986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:55<14:22,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1201 loss 0.2650386393070221 train acc 0.7722731057452124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [17:24<11:50,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1401 loss 0.21978427469730377 train acc 0.7716809421841542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:53<09:23,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1601 loss 0.5124690532684326 train acc 0.7725640224859462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [22:22<06:55,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1801 loss 0.4253244698047638 train acc 0.7716546363131593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [24:50<04:27,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 2001 loss 0.2212035059928894 train acc 0.7736131934032984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [27:19<01:57,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 2201 loss 0.6532238721847534 train acc 0.7725465697410268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [29:16<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 train acc 0.7723611699872828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:29<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val acc 0.7511299435028249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [03:08<00:00,  3.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.7598238482384824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    val_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length = valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(val_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        val_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} val acc {}\".format(e+1, val_acc / (batch_id+1)))\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Ggag6Uodec",
        "outputId": "87534f63-f032-483b-f15f-35da5a997ca2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:01<1:12:10,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 0.6688973307609558 train acc 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:22<25:28,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 201 loss 0.7691953778266907 train acc 0.6200248756218906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:45<23:23,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 401 loss 0.4682868719100952 train acc 0.6343516209476309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:08<20:47,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 601 loss 0.6916184425354004 train acc 0.6507903494176372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:31<18:40,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 801 loss 0.5742694735527039 train acc 0.6585518102372035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [11:54<16:13,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1001 loss 0.4651392102241516 train acc 0.6634615384615384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:17<13:47,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1201 loss 0.41570425033569336 train acc 0.6652789342214821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [16:40<11:23,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1401 loss 0.7902235388755798 train acc 0.670146324054247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:03<09:01,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1601 loss 0.4917345643043518 train acc 0.6771549031855091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [21:25<06:38,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1801 loss 0.44863927364349365 train acc 0.6858689616879511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [23:49<04:16,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 2001 loss 0.32389363646507263 train acc 0.6942778610694653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [26:11<01:52,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 2201 loss 0.5665483474731445 train acc 0.6984893230349841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [28:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 train acc 0.7016744383213226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:22<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val acc 0.7393361581920903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [02:58<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.7447493224932249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:00<36:05,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.5751675963401794 train acc 0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:24<25:44,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 201 loss 0.3932698667049408 train acc 0.7263681592039801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:46<23:22,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 401 loss 0.6633642911911011 train acc 0.7350374064837906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:10<20:53,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 601 loss 0.6553663015365601 train acc 0.7439683860232945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:33<18:37,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 801 loss 0.5631160140037537 train acc 0.7454744069912609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [11:56<16:09,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1001 loss 0.18791767954826355 train acc 0.7497502497502497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:19<13:48,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1201 loss 0.4414369761943817 train acc 0.7493755203996669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [16:42<11:21,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1401 loss 0.2817704975605011 train acc 0.7508922198429693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:05<09:01,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1601 loss 0.5917366743087769 train acc 0.7503903810118676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [21:28<06:38,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1801 loss 0.39683011174201965 train acc 0.7524292059966685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [23:51<04:16,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 2001 loss 0.3304728865623474 train acc 0.75555972013993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [26:14<01:53,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 2201 loss 0.6457557082176208 train acc 0.7556224443434802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [28:07<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 train acc 0.7555108096651123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:23<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val acc 0.7534604519774012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [02:58<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.7640582655826558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:00<36:32,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.6807453632354736 train acc 0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:24<25:44,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 201 loss 0.4563603699207306 train acc 0.7456467661691543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:46<23:19,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 401 loss 0.7492997646331787 train acc 0.7468827930174564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:10<20:56,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 601 loss 0.6527513861656189 train acc 0.7497920133111481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:32<18:36,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 801 loss 0.5160160064697266 train acc 0.7545255930087391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [11:55<16:13,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1001 loss 0.26789531111717224 train acc 0.7586163836163836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:18<13:47,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1201 loss 0.31600821018218994 train acc 0.7574937552039966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [16:41<11:22,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1401 loss 0.2218250036239624 train acc 0.7572269807280514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:04<09:01,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1601 loss 0.5497021675109863 train acc 0.7581980012492192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [21:27<06:38,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1801 loss 0.4404263496398926 train acc 0.7602720710716269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [23:50<04:17,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 2001 loss 0.2854260206222534 train acc 0.7624937531234383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [26:13<01:52,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 2201 loss 0.6269187331199646 train acc 0.7624375283961835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [28:06<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 train acc 0.7626642645188639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:22<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val acc 0.7513418079096046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [02:58<00:00,  4.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.7664295392953929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:00<36:35,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1 loss 0.4445200562477112 train acc 0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:23<25:42,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 201 loss 0.32116085290908813 train acc 0.7649253731343284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:46<23:19,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 401 loss 0.8012641072273254 train acc 0.7627805486284289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:09<20:54,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 601 loss 0.5715732574462891 train acc 0.7635191347753744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:32<18:34,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 801 loss 0.40335142612457275 train acc 0.7651373283395755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [11:55<16:08,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1001 loss 0.2124195098876953 train acc 0.7692307692307693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:18<13:50,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1201 loss 0.3500768542289734 train acc 0.7672772689425479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [16:41<11:23,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1401 loss 0.2232925295829773 train acc 0.7675767309064954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:04<09:00,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1601 loss 0.42359238862991333 train acc 0.7705340412242349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [21:27<06:38,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1801 loss 0.4814428985118866 train acc 0.7715852304275402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [23:50<04:17,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 2001 loss 0.19355183839797974 train acc 0.7733008495752124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [26:13<01:52,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 2201 loss 0.7743948698043823 train acc 0.7740231712857792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [28:06<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 train acc 0.7748516320474778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:23<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 val acc 0.7403248587570622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [02:58<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 test acc 0.7569444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2359 [00:00<36:37,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1 loss 0.5413323044776917 train acc 0.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 201/2359 [02:24<25:42,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 201 loss 0.46237531304359436 train acc 0.7804726368159204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 401/2359 [04:46<23:20,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 401 loss 0.6820467114448547 train acc 0.7814837905236908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 601/2359 [07:10<20:54,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 601 loss 0.8161017298698425 train acc 0.778910149750416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 801/2359 [09:33<18:40,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 801 loss 0.26254135370254517 train acc 0.7773096129837703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1001/2359 [11:56<16:13,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1001 loss 0.2039761245250702 train acc 0.7804695304695305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1201/2359 [14:19<13:47,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1201 loss 0.2311185747385025 train acc 0.7793505412156536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 1401/2359 [16:42<11:26,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1401 loss 0.20170021057128906 train acc 0.778283369022127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1601/2359 [19:05<09:01,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1601 loss 0.38777315616607666 train acc 0.7804497189256715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 1801/2359 [21:28<06:38,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1801 loss 0.4783456027507782 train acc 0.7813020544142143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 2001/2359 [23:51<04:17,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 2001 loss 0.1388564258813858 train acc 0.7817341329335332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2201/2359 [26:14<01:52,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 2201 loss 0.7910679578781128 train acc 0.7837914584279873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2359/2359 [28:08<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 train acc 0.7851844001695634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 590/590 [02:23<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 val acc 0.7413841807909605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 738/738 [02:58<00:00,  4.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 test acc 0.7552506775067751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    val_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length = valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(val_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        val_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} val acc {}\".format(e+1, val_acc / (batch_id+1)))\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxsMkjAL7xvM"
      },
      "outputs": [],
      "source": [
        "#torch.save(model, 'kobertmodel.pt')  \n",
        "\n",
        "#torch.save(model.state_dict(), 'kobertmodel_state_dict.pt')  \n",
        "\n",
        "#torch.save({\n",
        "#    'model': model.state_dict(),\n",
        "#    'optimizer': optimizer.state_dict()\n",
        "#}, 'kobertmodel.tar')  # \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"kobertmodel_state_dict.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5wA1h9QEqy5",
        "outputId": "a89eda11-7fee-4738-941e-af123b7f2607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint = torch.load('kobertmodel.tar')   \n",
        "model.load_state_dict(checkpoint['model'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])"
      ],
      "metadata": {
        "id": "IxdpWbrmFEc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK1Qwc0B8rAA"
      },
      "outputs": [],
      "source": [
        "model1 = torch.load('kobertmodel.pt')  \n",
        "model1.load_state_dict(torch.load('kobertmodel_state_dict.pt'))  \n",
        "\n",
        "checkpoint = torch.load('kobertmodel.tar')  \n",
        "model1.load_state_dict(checkpoint['model'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwdyyMY_Iygj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyCbonJPD1un"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "predictions =[]\n",
        "with torch.no_grad():\n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "    token_ids = token_ids.long().cuda()\n",
        "    segment_ids = segment_ids.long().cuda()\n",
        "    valid_length= valid_length\n",
        "    label = label.long().cuda()\n",
        "    out = model(token_ids, valid_length, segment_ids)\n",
        "    _, max_indices = torch.max(out, 1)\n",
        "\n",
        "    predictions.extend(max_indices.squeeze(0).detach().cpu().numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opMa-dQHWcLN"
      },
      "outputs": [],
      "source": [
        "true_labels =[]\n",
        "with torch.no_grad():\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        true_labels.extend(label.squeeze(0).detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "print(f1)\n",
        "\n",
        "f1 = f1_score(true_labels, predictions, average='micro')\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHxRG9ZNQBBV",
        "outputId": "f00c8925-cd12-4606-d5ce-23fbd303c4d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7729309228038384\n",
            "0.7565276364869449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUXiIFHTYb43"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "si6TbSdPbAut",
        "outputId": "b18c7d22-625b-4eb4-9c18-58b56786278c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gU1frA8e+bQhI6JIJI70VA0IggCghSBOwF0IvK5aqAiII/LFdQr6KiIgrSvdbrFRS8KIqAqAhYQIqA9CZC6D2EkJBk398fs6RAyhKymWzyfp5nn+ycOTvz7iTZd+ecmXNEVTHGGGOyEuR2AMYYYwo2SxTGGGOyZYnCGGNMtixRGGOMyZYlCmOMMdmyRGGMMSZblihMoSAi7UQkxo/bnyQiw9Mt9xeR/SISJyKR3p+1/LV/Y9xkicKcNxHZISKnvB+OR0VktohUvYDt+fQhLyItROQbETkmIkdE5DcR6ZPb/Z4PVe2nqi964wgFRgOdVLWkqh72/tyeF/sSkftFJMV7fGNFZLWIdD+rTpiIvCIiO72/iy0iMlRE5Kx6nUVkkYicEJGDIrJQRG7yYf8qIj0yKf8pk/o7ROT6dMuu/Z6Mf1iiMLl1o6qWBCoB+4G3c7MREQnxsV4r4AdgIVAHiAT6AzfkZr8XqCIQDqy70A1l8/5/9R7fssAEYJqIlE23fjrQAegKlAJ6Aw8CY9Jt+w5vvY+AKt64nwVuzCGs+4AjwL25eD8F6fdk8oqq2sMe5/UAdgDXp1vuCmxOtxwGjAJ24iSRSUCEd107IAZ4EtiH80F2CvAAcd7HJZns8ydgfDYxtQNi0i0/BWwDTgDrgVvTrauD80F2HDgEfOotF+BN4AAQC/wBNPau+wAYAdQDTgLqjfUH73oF6uTi/f8nk/dyP/BTuuXi3u1f6V3uACQAVc963VVAivf9iXf/Q8/zd1vd+7u4HUgGLs4qrsz+HnL6PdkjMB92RmEuiIgUB3oAS9IVj8T5QG2G86FVGeeb7BkXA+VxPpTuxfm2uUed5puSqronk320AmacR2jbgGuBMsC/gI9FpJJ33YvAt0A5nG/aZ86GOgFtvLGXAe4CDqffqKpuBi71LpZV1faZ7Pt83v+D2b0JEQkG+gBJwF/e4o7AUlXddVZsS3GSUAegPlCV8ztm4Pw+lqvq58AG4B5fX5jL35MJAJYoTG59ISLHcL6VdwReB/C2kT8IDFbVI6p6AngZ6JnutR7gOVVNVNVTPuyrHM7f6l5fg1PV6aq6R1U9qvopsAVo4V2dhPMhfYmqJqjqT+nKSwENAFHVDarq8z4hT99/S+/xTcA5O/mbqh7wrosi62Ox17s+Mt3y+bgX+MT7/BPOr/npvH9PJjBYojC5dYuqlsVpqx8ILBSRi4GLcJpKVng7M48Bc73lZxxU1YTz2NdRnA/XSjlVPENE7hWRVeliaIzzAQrwBE7TzG8isk5E/g6gqj8A44DxwAERmSIipc8jTsi797/Ee3zLAbNwzo7OOETWx6KSd/3hdMs+EZHWQE1gmrfoE6CJiDTzLicDoZm8NBQnyZ7378kEBksU5oKoaoqq/g+nbfwanA+pU8ClqlrW+yijTsds6svO3kwO+4gHfsVpN8+RiFQH3sFJYJHeD9y1OMkBVd2nqg+o6iXAQ8AEEanjXTdWVa8AGuE0Hw31ZZ/p5Ob9Z0lV43A6g3uLSHNv8XfAVWdfaSYiV+E0N/0AbAJ24eMx87oP5xitEpF9wNJ05eD0eVRLf2WVt7mpAvDX+f6eTOCwRGEuiDhuxvnmu0FVPTgf0m+KSAVvncoi0jmbzewHIkWkTDZ1ngDu914CGund7mUiMi2TuiVwPowPeuv1wTmjOBPznSJSxbt41FvXIyJXishV3stfT+I0+3hyOgbp5fL957TNI8C/8fZzqOp3wPfA5yJyqYgEi0hL4GNgoqpuUVUFhgDDRaSPiJQWkSARuUZEppy9DxEJx+mTeRCnb+XM4xHgbu/VWUtxjslTIhIuIiVw+mOWk9Z/cj6/JxMgLFGY3PpKROJwrg56CbhPVc9cLvoksBVYIiKxON+A62e1IVXdCEwFtnubay7JpM4vQHvvY7uIHAGmAN9kUnc98AbOt9v9QBPg53RVrgSWeuOfBTyqzj0QpXE+5I/ifPAdxtv3cp7O6/376C2gq4g09S7fDizAadaKw0kS7+J8sAOgqjNwLjT4O7AH51iMAL7MZPu34JwJfeQ949qnqvuA94AQoIuqJgLdSLtyaztwCXCXNzGd1+/JBA7x/n6NMcaYTNkZhTHGmGxZojDGGJMtSxTGGGOyZYnCGGNMtnwakK0giYqK0ho1argdhjHGBJQVK1YcUtWLcq55roBLFDVq1GD58uVuh2GMMQFFRP7KuVbmrOnJGGNMtixRGGOMyZYlCmOMMdmyRGGMMSZbliiMMcZkyxKFMcaYbPktUYjIeyJyQETWZrFeRGSsiGwVkTUicrm/YjHGGJN7/ryP4gOc2cI+ymL9DUBd7+MqYKL3pzGmKEk6BYnHQFPAk5z20BQ4dQgkq++zWYx8neWI2NmMlH2+r8l21O08jCuPtnX69HlNq3IOvyUKVV0kIjWyqXIzztj3ijNuf1kRqXS+cxQbYwLEiRiIWQS7FsCWmVC6OhxY6XZUhd7Qrzry+54Lm53WzTuzK+NM1XhGjLfsnEQhIg/izLxFtWrV8iU4Y0weiD8AK8fC0pfOXZdwOONyycoQFAIS7PwMCnHOLE7sgopXZLEDyaI4i/Ks6ufmNVnWz24/ebgtH+Nt3CSKsT/XyGb7OQuIITxUdQrOLFlER0fbTEvGFGT7V8K2r+C3VyAl8dz1kY2gXH2o2g6qtYdiZaB01XPrmVxZv/4gK1fu5W9/cyZDvPc2pe3jx6lZ84Vcb9PNRLEbZyL4M6p4y4wxgSTpFKz/CA6ugdUTMq/T8B64YghUtGtW/CU+PokRIxbx+uu/EBwstGxZhTp1yiMi1KhR9oK27WaimAUM9E66fhVw3PonjAkAcXvh+HbY/jX8NjLrei2ehlJVoOmDTjOS8Zs5c7bw8MPf8OefxwDo2/cKIiMj8mz7fvvtichUnEnYo0QkBngOCAVQ1Uk4k613xZmEPh7o469YjDEXSD0wt49z5pCVEhdDg7uh8rVQ95b8i60I2707lscem8eMGesBaNq0IpMmdaNVq7xtyvPnVU+9clivwMP+2r8xJo+sfBsWDDq3vHpH50qmLu9DJbuy3Q0PP/wNX365ieLFQ3nhhXY8+mhLQkLy/vY4Ox80xmQuZjF82ubc8n/8CWVq5Hs4xpGc7ElNBq++ej2hocG88UYnqlUr47d9WqIwxpxr/4pzk8TDRyH8wjpFTe4dP57AsGE/sHnzEebOvQcRoX79KKZPv9Pv+7ZEYYxxnIhx7nlY/nrG8ssfhXZv5nCtv/EXVWX69PU89thc9u6NIzhYWLVqH82bX9hNdOfDEoUxRVVyAqx4E9ZMhtgsZsm87RuoeUP+xmVSbdt2hIED5zB37lYAWrWqwqRJ3WnatGK+xmGJwpiixJMMe36BrV84SSIzlVrBFY9BvTvtLMJFo0b9wvDhC0hISKZs2XBeffV6/vGPywkKyv/fiSUKY4qCfcvgvy0yX1eiEnScArW6ZjMAn8lv8fFJJCQk07t3U0aN6kSFCiVci8UShTGFWdwemFz53PLiFaHkJXDtq1CjY/7HZc5x8OBJNm06zDXXOOPZPflka9q1q0GbNtVdjswShTGFkycZ1n4A8x/IWN5xMjR5wJqUChCPR3nvvd954on5hIQEsXHjQMqXjyAsLKRAJAmwRGFM4aEKB1bB/7o4o7am1+QB6DTFnbhMltauPUC/fl/z88/OQNodO9YiPj6J8uXzbviNvGCJwphAd3gDbJwGm6bB0c3nru/+KdS/K//jMlk6efI0L7ywkNGjl5Cc7KFixRK89VYXevS4FCmAZ3uWKIwJRMf/hI2fOsnh4Oq08oiLnKuVGvSAKpncVW0KhDvumM7cuVsRgQEDonnppQ6ULRvudlhZskRhTKCI2wObPnOSw96laeVhZaDu7VC/J1S7zkZqDQBPPtma/fvjmDixG1ddVcXtcHJkf1HGFGTxh2DL505y2LWQ1DmRQ0tA7ZuhQU+o3glCwlwN02QtOdnD228vZceOY4wZ49y82K5dDZYvf9CVeyJywxKFMQVN4nHnhriN0+Cv+aApTnlwGNTs6iSHWt2cZGEKtN9+281DD33NqlX7AHjwwSu49NIKAAGTJMAShTEFQ1K8MxHQxqnw5zeQctopl2BnCI36PaHOzU4zkynwjh1L4J///J5Jk5ajCtWrl2HcuK6pSSLQWKIwxi3JibBjntOstG0WJJ30rhBnPun6PZ2+h+JRbkZpztO0aWt57LG57N9/kpCQIB5/vBXDh7ehRIliboeWa5YojMlPnmTY+YPTrLT1f04z0xmVWjrNSvXudO6aNgHp22+3sX//SVq3rsrEid1o0iR/B/DzB0sUxvibemD3z05y2DwdTh1MW3fRZc6ZQ4MeUKamezGaXEtMTGb37hPUqlUOgNde68i111bjvvuaBVQ/RHYsURjjD6rO5D8bp8KmTyFud9q6cvWgQS+o3wMiG7oXo7lgP/zwJ/37zyYoSFi9uh/FigUTFVWcPn2aux1anrJEYUxeOrQ27S7pY9vSyktX95459HTOIgrg3bfGd/v3x/F//zefjz9eA0CDBlHExMSmnlUUNpYojLlQR7c6iWHjNDi8Lq28xMVQ7y4nOVRqacmhEPB4lHfeWcFTT33PsWMJhIeHMGzYtQwd2ppixYLdDs9vLFEYkxuxu2DzZ07T0v4VaeXh5Z0rlRr0cobQCCq8Hx5F0a23fsqsWZsA6Ny5NuPHd6V27fIuR+V/liiM8dXJ/bB5hnP2sPuntPJipaDOLU7TUvXrIThwL4M02bvttgb89ttuxozpwp13NiqQA/j5gyUKY7KTcBS2zHSSw87vnSuYAELCodaNTrNSjRsgtGANC23yxqxZm4iJiWXAgCsBuPfey7jttoaUKlW0hkyxRGHM2U7HOTfAbZwGO+aCJ8kpDwpNG0Kj9k3OmYQplHbuPM6gQXP48stNhIUF06VLHWrVKoeIFLkkAZYojHEkJ8Cfc5zksP0rSD7llEsQVLveSQ51boWIwt8eXZQlJaUwduxSnnvuR06eTKJUqWKMGNGe6tWL9tAplihM0ZWSBDu/894lPRNOn0hbd0lr713SdzhXL5lCb8mSGB566GvWrNkPwJ13NuLNNztTuXJplyNznyUKU7R4UiBmkdPnsPlzSDictq7iFU6HdP27oHQ192I0rhg+fAFr1uynZs2yjBvXla5d67odUoFhicIUfqrORD+bpjkT/5zcm7aufEPnUtYGPaGcfTAUJarKiROnKV3a6XMYN+4GPvpoNc8804bixUNdjq5gsURhCidVOLgmbQiN2B1p68rUchJD/Z4Q1dhuhCuCNm06xIAB3yAC8+f3RkSoXz+Kl17q4HZoBZIlClO4HNmUNoTGkY1p5SUvccZWatALKkZbciiiEhKSeeWVxYwc+TOnT6cQGRnBjh3HqFmzcA69kVcsUZjAd3yHc9awcRocXJVWHhHlDNndoCdUvsa5gskUWfPnb2PAgG/YuvUIAH//ezNee60jkZHFXY6s4PNrohCRLsAYIBj4t6qOPGt9NeBDoKy3zlOq+o0/YzKFRNxeZ8jujdNg769p5WFloM5tTnKo1h6C7LtQUaeq9O07i/ffd75ENGp0EZMmdePaa6u7HFng8Nt/kYgEA+OBjkAMsExEZqnq+nTVhgGfqepEEWkEfAPU8FdMJsCpws/DYelLGctDijs3wDXoCTW6QEjRuyHKZE1EqFGjLBERITz7bFuGDGlVqAfw8wd/ft1qAWxV1e0AIjINuBlInygUOHORchlgjx/jMYHKkwwzb3Tukk6vRhe49H6o3R1CS7gSmimYVq3ax969J7jhBudKtiefbE3v3k2tLyKX/JkoKgO70i3HAFedVed54FsReQQoAVyf2YZE5EHgQYBq1ez69iJDPTDrDudmuLM98Jfd62DOceJEIs899yNjxiwlMjKCjRsHUr58BGFhIZYkLoDbDbi9gA9U9Q0RaQX8R0Qaq54Zec2hqlOAKQDR0dHqQpwmv22aDl/fdW55v31QIvDnIDZ5S1X54ouNDBo0l5iYWIKChLvvbkJoqF3AkBf8mSh2A1XTLVfxlqXXF+gCoKq/ikg4EAUc8GNcpiBLioexJXFaJdMZFGfNSyZTf/11jIED5/D115sBiI6+hMmTu3P55ZVcjqzw8GeiWAbUFZGaOAmiJ3D3WXV2Ah2AD0SkIRAOHMQUTce2wbt1MpbdPg9qdHInHlPgqSq33/4ZK1bspXTpMF5+uT39+kUTHGxnEnnJb4lCVZNFZCAwD+fS1/dUdZ2IvAAsV9VZwOPAOyIyGOcr5P2qak1LRU3cHphcOWNZeCQMOGg3xplMeTxKUJAgIowa1YlJk5bz5pudqVTJhn73Bwm0z+Xo6Ghdvny522GYvBJ/ECZWyFh2xWBoN9qdeEyBdvhwPE899R0A77xzk8vRBBYRWaGq0bl5rdud2aaoUoX/dc14yWvDv0HX/7gXkymwVJWPPlrN//3ffA4diqdYsWCee64dVarYEOD5wRKFyT+q8Nd8WPwUHPg947orHod2o9yJyxRoGzYcpH//2Sxc+BcA7drVYOLEbpYk8pElCpM/Tp+At7P4x+631yYHMudQVZ59dgGvvvozSUkeoqKK88YbnejduylifVf5yhKF8T/1ZEwSQSHQ+iW4fBCEhLsXlynQRITdu0+QlOThgQcuZ+TI6ylfPsLtsIokSxTGvzZ8At/ck7bcoBd0+8S9eEyBtmfPCQ4diqdpU+emytde60jfvs1p3druwneTJQrjHwf/gNm94PC6tLL6PSxJmEylpHiYOHE5zzzzA5Url2LVqn4UKxZMVFRxoqIsSbjNEoXJe3t+halXZyzrvQoqXOZOPKZAW7lyLw899DXLlztjgrZpU53Y2ESiomyeiILCEoXJW6fjMiaJendBh3FQ/CL3YjIFUmxsIsOH/8C4ccvweJQqVUozdmwXbrmlgXVWFzA+JwoRKa6q8f4MxgQwVZjXF9a9n1bW9b/Q8OxRW4xxrmhq0+Z9Vq/eT3CwMGRIS55/vh2lStlcIgVRjgOiiMjVIrIe2OhdvkxEJvg9MhNYfnk2Y5K45mVLEiZLIsLgwS1p0aIyy5c/yBtvdLYkUYDlOISHiCwF7gBmqWpzb9laVW2cD/Gdw4bwKIB+fBxWpBtyo/9+KF4h6/qmyDl9OoXRo38lOFgYOrQ14JxVeDxqA/jlE78P4aGqu85qM0zJzc5MIfTrCxmTxH1rLUmYDBYv/ot+/Wazfv1BwsKCuffey6hYsSQiQnCw9UUEAl8SxS4RuRpQEQkFHgU2+DcsU+B5UuDNs/58+h+wTmuT6tCheJ54Yj7vv78KgLp1yzNhQjcqVizpcmTmfPmSKPoBY3CmNt0NfAsM8GdQpoCLWQyftslY9vfNliQM4DQpffDBKoYOnc/hw6coViyYp5++hqeeuobwcLvQMhD58lurr6r3pC8QkdbAz/4JyRRoW2bCrNvSlmt0htvnZl3fFEkff/wHhw+fon37mkyY0JX69aPcDslcAF8SxdvA5T6UmcJs/X9g6ctwZGNa2Z0/QLXr3IvJFBjx8UkcP55ApUqlEBEmTOjKsmV7uOeeJnZPRCGQZaIQkVbA1cBFIjIk3arSODPWmaLAkwyLn4blZw0BftcCqNrOlZBMwTJnzhYefvgbatUqx/z5vRER6tePsrOIQiS7M4piQElvnfTzC8biXC5rCjtPMrwZmrGsy4dQ8wbrjzDs3h3LY4/NY8aM9QCUKhXG4cOnbOiNQijLRKGqC4GFIvKBqv6VjzGZgiBuL0y+JG05KBR6/w5Rl7oXkykQUlI8jB+/jGHDfuDEidOUKBHKCy9cx6BBVxESYvdEFEa+9FHEi8jrwKVA6uQBqtreb1EZdy1+Gn4bmbZcrh78fZN78ZgCw+NR2rb9gJ9/3gXALbc0YMyYLlSrVsblyIw/+ZL+/4szfEdN4F/ADmCZH2Mybko6lTFJNP67JQmTKihI6NSpNlWrlubLL3syc2YPSxJFgC9DeKxQ1StEZI2qNvWWLVPVK/MlwrPYEB5+tH8FfJzuDv9HT9kMdEWcqvLZZ+sICQni9tsbAZCYmExSkoeSJYu5HJ05H/4ewiPJ+3OviHQD9gDlc7MzU4D9PByWjEhbrt/DkkQRt23bEQYM+IZvv93GRRcVp337mpQrF0FYWAhhNn5fkeJLohghImWAx3HunygNPObXqEz+ilmUMUn0WAxVrnEvHuOqxMRkXn/9F156aTEJCcmUKxfOSy+1p0wZ++JQVOWYKFT1a+/T48B1kHpntgl0SfEw7Vo4sDKtzJqbirQff9xB//6z2bjxEAC9ezdl1KhOVKhQwuXIjJuyu+EuGLgLZ4ynuaq6VkS6A/8EIoDm+ROi8ZuxZ/3z91hsSaIIS0nxMGCAkyTq149k4sRuXHddTbfDMgVAdmcU7wJVgd+AsSKyB4gGnlLVL/IjOONH79RIe16sFPTbC6H2rbGo8XiUhIRkihcPJTg4iIkTu7Fo0V888URrwsJsAD/jyO4vIRpoqqoeEQkH9gG1VfVw/oRm/Gb/SohNdw/lI7HuxWJc88cf++nXbzYNGkTy7rs3A9C2bQ3atq3hbmCmwMkuUZxWVQ+AqiaIyHZLEoXA511gx7y05UFx7sViXHHy5GleeGEho0cvITnZw59/HuXo0VOUKxfhdmimgMouUTQQkTXe5wLU9i4LoGfuqTAB4tQRmBCZsazls9bcVMR89dUmBg6cw86dxxGBAQOieemlDpQta31TJmvZJYqG+RaF8a+UpIxJIrQkDDwGQTYIcFGRnOyhR48Z/O9/zuSUzZpdzOTJ3WnRorLLkZlAkN2ggDYQYGGw7HVY9ETacrvRcMVg9+IxrggJCaJMmTBKlizGiy9ex8CBLWwAP+OzHIfwuKCNi3TBmUY1GPi3qo7MpM5dwPOAAqtV9e7stmlDeJyHj6OdYTnOKFML/rHNvXhMvlq6NAaAq66qAsDhw/GcOpVMlSql3QzLuMTfQ3jkivc+jPFARyAGWCYis1R1fbo6dYGngdaqelREKvgrniLnxO6MSaLHQqh8rXvxmHxz7FgCTz/9HZMnr6BBgyhWrepHsWLBREbaPBEmd3xKFCISAVRT1fMZRrQFsFVVt3u3MQ24GVifrs4DwHhVPQqgqgfOY/smK6dPwJQqacuP+++s0RQcqsrUqWsZMmQe+/efJCQkiJtuqk9KigeblNJciBwbKUXkRmAVMNe73ExEZvmw7crArnTLMd6y9OoB9UTkZxFZ4m2qMrmlHpjbB95O17RQ93b34jH5ZsuWw3Tq9DH33PM/9u8/SevWVfn994cYOfJ6IiJCc96AMdnw5YzieZyzgx8BVHWViOTVff0hQF2gHVAFWCQiTVT1WPpKIvIg8CBAtWrV8mjXhdDKMbDug7Tli1vAjdNdC8fkj6SkFNq3/4iYmFjKl4/gtdeup0+f5gQFiduhmULCp2HGVfW4SIY/Ol/aMnbjDAFyRhVvWXoxwFJVTQL+FJHNOIkjw8RIqjoFmAJOZ7YP+y56YhbDj0PSlgfFQ6jdQFWYqSoiQmhoMC+91J4FC3bw2mvXc9FFdm+MyVu+XB+3TkTuBoJFpK6IvA384sPrlgF1RaSmiBQDegJnN1l9gXM2gYhE4TRFbfc1eIPTH/GGwKdt0spun2dJohDbvz+O3r1nMmLEotSye++9jPffv9mShPELXxLFIzjzZScCn+AMN57jfBSqmgwMBOYBG4DPVHWdiLwgIjd5q80DDovIemABMNSGCTkPp09k7I8A6PUL1OjkTjzGrzweZfLk5TRoMJ6PP17D6NFLOHEi0e2wTBHgy1Sol6vqymwr5SO7j8Irdie8Uz1tuckD0GmKe/EYv1q9eh/9+s1myRLn3oguXeowfnxXatUq53JkJlD4+z6KN0TkYmAG8Kmqrs3Njkwe8aTA551g5w9pZQ16WZIopJKSUnj66e95660lpKQolSqVZMyYLtxxRyPO6jc0xm9ybHpS1etwZrY7CEwWkT9EZJjfIzOZm313xiRxxRDo9ol78Ri/CgkJ4vff9+HxKI880oINGx7mzjsvtSRh8tV5DeEhIk2AJ4AeqlrMb1Flo0g3PcXugnfSXR78wA4oXT3L6iYw7dx5nJQUDzVrOs1KW7Yc5vjxRKKjL3E5MhPILqTpyZcb7hqKyPMi8gdw5oqnKjm8zOQ11YxJ4qE9liQKmaSkFEaN+oWGDcfzwANfceZLXN26kZYkjKt86aN4D/gU6Kyqe/wcj8lMyml4KyxtuckDULKSe/GYPPfrr7vo1282a9bsB6B8+Qji45MoUcKVE3djMsgxUahqq/wIxGQhs0tgreO60Dh69BRPPfUdU6Y4FxbWrFmW8eO7csMNdV2OzJg0WSYKEflMVe/yNjml78iwGe7yS9wemJxueKzgYvBognvxmDyVmJhMs2aT2bnzOKGhQQwdejXPPNOG4sVtbCZTsGR3RvGo92f3/AjEpJMU78wlcWRDWln9HtB9mnsxmTwXFhZC377N+f77P5k4sRuNGl3kdkjGZMqXG+5eVdUncyrLL0Xiqqc3zrr0seUwaP2iO7GYPJOQkMwrryymfv0o7r67CeBMURocLHa5q/E7f99w1xE4OynckEmZyQvpk0TERc4lsKE24Uygmz9/GwMGfMPWrUeoUKEEt97agIiIUJuO1ASE7Poo+gMDgFoisibdqlLAz/4OrMjZ9jV8cWPGsgE2j1Og27cvjiFD5jF1qjOgwaWXXsSkSd1tjggTULI7o/gEmAO8AjyVrvyEqh7xa1RFiaqTILbPTisLLQGD4tyLyVywlBQPkyev4J///J7jxxOJiAjhuefaMnhwK4oVs9nmTGDJLlGoqu4QkYfPXiEi5S1Z5JHx5SEx3TxNvX6FS1q6F4/JEykpyttv/8bx44l07VqXcRKahk8AACAASURBVONuSL3T2phAk9MZRXdgBc7lsel72xSo5ce4iobYXRmTRP/9ULyCe/GYC3LiRCIpKUrZsuEUKxbMO+/cyP79cdx2W0PrrDYBLctEoardvT/zatpTk15KUsYhOR63ifsClaoyc+ZGBg2aQ+fOtXn33ZsBuOYam7bXFA6+jPXUWkRKeJ//TURGi4j9B1yImMXwVrqhGZo+5F4s5oLs2HGMm26axu23f8bu3SdYu/YgCQnJbodlTJ7y5dq8iUC8iFwGPA5sA/7j16gKs2WjMk5bWrIyXD/RvXhMriQlpfDqqz/RqNF4vv56M6VLhzFu3A388svfCQ/35apzYwKHL3/RyaqqInIzME5V3xWRvv4OrNCJPwgTz+p/6PkTVG7tTjwm1+Ljk2jZ8t/88Ydz+XLPno0ZPboTlSqVcjkyY/zDl0RxQkSeBnoD14pIEGAXgftKFUZncuLW/wAUtyEbAlHx4qFER19CfHwSEyZ0o1On2m6HZIxf+ZIoegB3A39X1X3e/onX/RtWIXJ2kqjeEW77BoKseSJQqCoffbSa2rXLp3ZQv/lmZ4oVC7Yb50yR4Msw4/tE5L/AlSLSHfhNVT/yf2iFwNe9Mi7blU0BZ8OGg/TvP5uFC/+iYcMoVq3qR7FiwZQpE+52aMbkG1+ueroL+A24E7gLWCoid/g7sID3/UDYlG601yEe92Ix5+3UqSSGDfuByy6bxMKFf3HRRcV5+ulrCA21sZlM0eNL+8czwJWqegBARC4CvgNm+DOwgKUKEyIh4Wha2aCTYDdcBYy5c7fy8MPfsH278zt84IHLGTnyesqXj3A5MmPc4UuiCDqTJLwO49tltUXP8tGw8PGMZQ/stNFfA0hc3Gl6957JoUPxNG5cgUmTutG6td02ZIo2XxLFXBGZB0z1LvcAvvFfSAEq8XjGJFG6OvxjO4jl1IIuJcWDx6OEhgZTsmQxxozpQkxMLIMHtyQ01AbwM8aXzuyhInIbcI23aIqqzvRvWAEmORHGlU1b7rsNytpQWIFgxYo9PPTQ19x8c32GD28LkDqpkDHGkd18FHWBUUBt4A/g/1R1d34FFjA8yTAm3RUwlw2wJBEAYmMTGT78B8aNW4bHo8TGJvLUU9fYGYQxmciuXeQ94GvgdpwRZN/Ol4gCzfx+ac+v/hdcP969WEyOVJXp09fRoME4xo79DREYMqQlK1c+ZEnCmCxk1/RUSlXf8T7fJCIr8yOggHJ4I6x9N2251bPuxWJydOJEIj16zGDOnK0AXHVVZSZN6k6zZhe7HJkxBVt2iSJcRJqTNg9FRPplVS3aiWPjNJid7oa6e9dkXdcUCCVLFiMxMYUyZcIYOfJ6HnzwCoKC7LJlY3KSXaLYC4xOt7wv3bIC7f0VVIGWkgQfNoajm9PKOk6Bi6wDtCBatOgvKlUqSd26kYgI7713E+HhIVSsWNLt0IwJGNlNXHRdfgYSMNLPIwFw3x8Q1didWEyWDh2K54kn5vP++6vo0KEm8+f3RkSoXr1szi82xmRgI9Odj5+fy7hsYzcVOB6P8sEHqxg6dD5HjpyiWLFgrr22GikpSkiINTMZkxt+TRQi0gUYAwQD/1bVkVnUux1nSJArVXW5P2PKldhdGactBXjstDuxmCytW3eA/v1ns3jxTgA6dKjJhAndqFcv0uXIjAlsfksUIhIMjAc6AjHAMhGZparrz6pXCngUWOqvWC7Iwidg+VmjqvfdCsE2vHRBcvx4Ai1bvktc3GkqVCjB6NGduPvuJoiNsWXMBcsxUYjzn3YPUEtVX/DOR3Gxqv6Ww0tbAFtVdbt3O9OAm4H1Z9V7EXgVGHq+wfvd3t8yJomWw6D1i+7FY86hqogIZcqE8+STrdm9O5aXX+5AuXI2gJ8xecWXgYgmAK2AM9eCnsA5U8hJZWBXuuUYb1kqEbkcqKqqs7PbkIg8KCLLRWT5wYMHfdh1HvnkqrTnAw5bkihAdu+O5Y47PuPjj9MuS37mmWuZOLG7JQlj8pgvieIqVX0YSABQ1aNAsexfkjPvlKqjgcdzqquqU1Q1WlWjL7oon6YP/fLWtOfXjYGI8vmzX5Ot5GQPY8YsoUGD8Xz++Qaee+5HUlKcuT6smckY//CljyLJ29+gkDofhS+z8OwGqqZbruItO6MU0Bj40fsPfjEwS0RucrVDOykexpbIWHb5IHdiMRksW7abfv1ms3LlXgBuuaUBY8d2ITjYRug1xp98SRRjgZlABRF5CbgDGObD65YBdUWkJk6C6Ikz9zYAqnociDqzLCI/4gw86F6SUM+5SWJwsjuxmFQnT57mySe/Y8KEZahCtWplePvtG7jppvpuh2ZMkeDLMOP/FZEVQAec4TtuUdUNPrwuWUQGAvNwLo99T1XXicgLwHJVnXWBseetU4dhQlTGMrtPokAICQniu++2ExQkDBnSiueea0uJEhfc+mmM8ZGoZv9h6L3K6RyqutMvEeUgOjpaly/P45MOVRh9VvPF4GQIstFE3bJt2xHKlg0nMtKZHXDZst2Eh4fQpElFlyMzJjCJyApVjc7Na31p3J2NM9z4bOB7YDswJzc7K7Cmtk573uhe50zCkoQrEhOTGTFiEY0bT+TJJ79LLb/yysqWJIxxiS9NTxlGu/Ne0jrAbxHlt7++h72/pi3f8KF7sRRxP/64g/79Z7Nx4yHAucIpJcVjndXGuOy878xW1ZUiclXONQPAgsGw8q205UHx7sVShB04cJKhQ+fz0UerAahfP5KJE7tx3XU1XY7MGAO+3Zk9JN1iEHA5sMdvEeUX1YxJ4pavINRu1Mpvhw7F07DheI4cOUVYWDDPPHMtTzzRmrAwG6/SmILCl//GUumeJ+P0VXzun3Dyyek4eDvd2xp4HMJKuxdPERYVVZybb65PTEwsEyZ0o04du7HRmIIm20ThvdGulKr+Xz7F439nXwZbqqoliXx08uRpXnhhId261aNNm+oATJjQjbCwYLuz2pgCKstEISIh3nshWmdVJyClTxJhZeGBv9yLpYj56qtNDBw4h507jzN79hbWrOlPUJAQHm7NTMYUZNn9h/6G0x+xSkRmAdOBk2dWqur//Bxb3ko6BWOLpy03/jt0fte9eIqQXbuO8+ijc5k5cyMAzZtfzOTJ3W2+amMChC9f5cKBwzhzZCvO3dkKBE6iOLoV3qubthwSDp3ecS+eIiI52cPYsUt59tkFnDyZRMmSxRgx4joefrgFISF2yasxgSK7RFHBe8XTWtISxBmBMbZF/AH46i6IWZhWVvc2uCmw++IDRWxsIq+88hMnTyZx++0NeeutLlSpYv1BxgSa7BJFMFCSjAnijIKfKI5tg3frZCxr+Sy0/pc78RQRx44lEBERQlhYCOXLRzB5cnfCwoLp1q2e26EZY3Ipu0SxV1VfyLdI8lJibMYkUfla6DgFIhu4F1Mhp6pMnbqWwYPnMXDglQwf3haA225r6HJkxpgLlV2iCNyextk9057b9KV+t3nzYQYMmM333/8JwKJFO1OnKDXGBL7sEkWHfIsiL53cB3+mG7PQkoTfJCQk8+qrP/Hyyz9x+nQK5ctH8PrrHbn//maWJIwpRLJMFKp6JD8DyTOTKqU977vVvTgKuX374mjT5n22bHH+TO6/vxmvv96RqKjiObzSGBNoCtedTvP6pj2vcyuUre1eLIVcxYolqFq1DCEhQUyc2I22bWu4HZIxxk8KT6LY9jWsfS9t2S6BzVMej/LOOyu47rqa1KsXiYjwySe3Ua5cBMWK2dwdxhRmheOup5+Hwxc3pi33PwDWRp5nVq/eR+vW79Gv32wGDJjNmVkRK1YsaUnCmCKgcJxRLBmR9rznT1D8IvdiKUTi4k7z/PM/8tZbS0hJUS65pBT9+uVqJkVjTAAL/ETxydVpz/tug7K13IulEPnii4088sgcYmJiCQoSHnmkBSNGtKd06TC3QzPG5LPATxTppzG1JJEndu+OpWfPGSQmpnDFFZWYNKk70dGXuB2WMcYlgZ0oPMlpz/++xb04CoGkpBRCQoIQESpXLs1LL7WnWLFgBgy40uasNqaIC+xPgJ+Hpz23s4lc++WXXVxxxRQ+/nhNatnjj1/NI49cZUnCGBPAieLwRvhtZNqyBO5bccuRI6d46KGvaN36Pf744wATJixPvaLJGGPOCNymp8/apj3v/bt7cQQgVeXjj9fw+OPfcvBgPKGhQTzxRGueeeZaG3rDGHOOwE0UCUednzU6Q4Vm7sYSQPbvj6NXr89ZsGAHAG3bVmfixG40bGiXFBtjMhe4icKT5Py8YrC7cQSYsmXD2bs3jqio4owa1ZF7773MziKMMdkKzESRdCrteYXL3YsjQMyfv43LL69EZGRxwsJCmD79TipVKklkpA3gZ4zJWWD2AKckpD23u7CztHfvCXr1+pxOnT7mySe/Sy1v3LiCJQljjM8C84ziV5vONDspKR4mT17B009/T2xsIhERIdSvH2mTCRljciUwE8XKMW5HUGCtXLmXfv2+ZtmyPQB061aXceO6UqNGWZcjM8YEqsBMFCERkHwKbv3a7UgKlB07jtGixTukpCiVK5di7NgbuPXWBnYWYYy5IH5NFCLSBRgDBAP/VtWRZ60fAvwDSAYOAn9X1b9y3HCytzO7Stvs6xUxNWqUpU+fZpQqFca//tWOUqVsAD9jzIXzW2e2iAQD44EbgEZALxFpdFa134FoVW0KzABey3HDZy6LBQgulkfRBqYdO45x441TWbhwR2rZlCk3Mnp0Z0sSxpg8488zihbAVlXdDiAi04CbgfVnKqjqgnT1lwB/y3Gr6kl7XkQTRVJSCqNH/8q//rWQU6eSOXQonl9/daaBtWYmY0xe82eiqAzsSrccA1yVTf2+wJzMVojIg8CDADWreYe7Ll0jD0IMPD/9tJN+/b5m3bqDAPTs2ZjRozu5HJUxpjArEJ3ZIvI3IBrItNNBVacAUwCimzVW2JOP0RUMR4+eYujQ+bz7rjOuVe3a5ZgwoRudOtV2OTJjTGHnz0SxG6iabrmKtywDEbkeeAZoq6qJOW71zM12cedsqlDzeJQvv9xEaGgQTz11DU8/fQ0REaFuh2WMKQL8mSiWAXVFpCZOgugJ3J2+gog0ByYDXVT1gE9bPTMMdvn6eRhqwbRx4yFq1ixLWFgIkZHF+e9/b6NatTI0aBDldmjGmCLEb1c9qWoyMBCYB2wAPlPVdSLygojc5K32OlASmC4iq0RkVo4bTopzfhav4I+wC4T4+CSeeeZ7mjadyGuv/Zxa3qlTbUsSxph859c+ClX9BvjmrLJn0z2//rw3mnTS+Rla6sKCK6Dmzt3KgAGz+fPPYwAcOhTvckTGmKKuQHRmn5cziaJMDVfDyGt79pzgscfmMn26c/VwkyYVmDSpO1dfXTWHVxpjjH8FXqI4o86tbkeQZzZvPkx09BROnDhN8eKhPP98Wx57rCWhocFuh2aMMQGcKMrVdTuCPFO3bnmuvLIyJUqE8vbbN1C9ug3gZ4wpOAI3UZS8xO0Ici02NpFnn13AgAFXUq9eJCLCrFk9KVGiaN5pbowp2AI3UQQgVWXGjPU8+uhc9u6NY+PGQ8yd64xaYknCGFNQBWaiqBjtdgTnbfv2owwc+A1z5mwFoGXLKrz66vlf9GWMMfktMBNFADl9OoVRo37hxRcXkZCQTNmy4Ywc2YEHHriCoCAbwM8YU/BZovCzXbuO88ILC0lMTOGee5rwxhudqFixpNthGWOMzwIzUSQedTuCbB09eoqyZcMREWrXLs+YMV2oU6c8HTrUcjs0Y4w5b34bwsOvwiPdjiBTHo/y3nu/U6fO23z88ZrU8oceirYkYYwJWIGZKKIaux3BOdatO0C7dh/Qt+8sjhw5ldppbYwxgS4wm54KkPj4JF58cSGjRv1KcrKHChVK8OabnenVq+AlM2OMyQ1LFBdg8+bDdO78MTt2HEME+vW7gpdf7kC5chFuh2aMMXnGEsUFqF69DOHhIVx2WUUmTepOy5ZV3A7JFCBJSUnExMSQkJDgdiimCAkPD6dKlSqEhubdxGaWKM5DcrKHSZOW06tXYyIjixMWFsLcufdQuXJpQkICs7vH+E9MTAylSpWiRo0aiNg9M8b/VJXDhw8TExNDzZo182y79unmo99+202LFu/wyCNzePLJ71LLq1cva0nCZCohIYHIyEhLEibfiAiRkZF5fhYbmGcU8QfzbVfHjyfwzDM/MGHCMlShWrUy3Hxz4Z+G1eQNSxImv/njby4wE0X1Dn7fhary6afrGDx4Hvv2xRESEsSQIS159tm2NoCfMaZIsTaTLKxevZ9evT5n3744rr66KitXPsirr3a0JGECSnBwMM2aNaNx48bceOONHDt2LHXdunXraN++PfXr16du3bq8+OKLqGrq+jlz5hAdHU2jRo1o3rw5jz/+uBtvIVu///47ffv2dTuMLCUmJtKjRw/q1KnDVVddxY4dO86ps2nTJpo1a5b6KF26NG+99RYAq1evplWrVjRp0oQbb7yR2NhYAP744w/uv//+/HsjqhpQjyuqoLriLfWH5OSUDMuDB8/Vd95ZoSkpHr/szxRu69evdzsELVGiROrze++9V0eMGKGqqvHx8VqrVi2dN2+eqqqePHlSu3TpouPGjVNV1T/++ENr1aqlGzZsUFXV5ORknTBhQp7GlpSUdMHbuOOOO3TVqlX5us/zMX78eH3ooYdUVXXq1Kl61113ZVs/OTlZK1asqDt27FBV1ejoaP3xxx9VVfXdd9/VYcOGpdbt0KGD/vXXX5luJ7O/PWC55vJz1/UP/vN9+CtR/PDDdm3QYJwuXLgjz7dtiqYM/6yj8M8jB+kTxcSJE7V///6qqvrvf/9be/funaHu1q1btUqVKqqq2rt3b3333Xdz3P6JEyf0/vvv18aNG2uTJk10xowZ5+x3+vTpet9996mq6n333acPPfSQtmjRQgcPHqzVq1fXo0ePptatU6eO7tu3Tw8cOKC33XabRkdHa3R0tP7000/n7Ds2Nlbr1auXurx06VJt2bKlNmvWTFu1aqUbN25UVdX3339fb7zxRr3uuuu0TZs2GhcXp3369NErr7xSmzVrpl988YWqqv755596zTXXaPPmzbV58+b6888/5/j+c9KpUyf95ZdfVNVJUpGRkerxZP3Fc968eXr11VenLpcuXTq1/s6dO7Vhw4ap69566y199dVXM91OXieKwOyjyEMHDpxk6ND5fPTRagBGj/6VNm2quxyVMXkrJSWF77//PrWZZt26dVxxxRUZ6tSuXZu4uDhiY2NZu3atT01NL774ImXKlOGPP/4A4OjRnAfsjImJ4ZdffiE4OJiUlBRmzpxJnz59WLp0KdWrV6dixYrcfffdDB48mGuuuYadO3fSuXNnNmzYkGE7y5cvp3HjtBEQGjRowOLFiwkJCeG7777jn//8J59//jkAK1euZM2aNZQvX55//vOftG/fnvfee49jx47RokULrr/+eipUqMD8+fMJDw9ny5Yt9OrVi+XLl58T/7XXXsuJEyfOKR81ahTXX59xjpndu3dTtWpVAEJCQihTpgyHDx8mKioq02Mzbdo0evXqlbp86aWX8uWXX3LLLbcwffp0du3albouOjqakSNH8sQTT+R0yC9YkU0UHo/y7rsrefLJ7zh6NIGwsGCGDWvD0KFXux2aKYwe15zr+MGpU6do1qwZu3fvpmHDhnTs2DFPt//dd98xbdq01OVy5crl+Jo777yT4OBgAHr06MELL7xAnz59mDZtGj169Ejd7vr161NfExsbS1xcHCVLpg3Rv3fvXi666KLU5ePHj3PfffexZcsWRISkpKTUdR07dqR8+fIAfPvtt8yaNYtRo0YBzmXMO3fu5JJLLmHgwIGsWrWK4OBgNm/enGn8ixcvzvE95sbp06eZNWsWr7zySmrZe++9x6BBg3jxxRe56aabKFYsrY+0QoUK7Nmzxy+xnK1IJoo//zzK3/42k19+cbJzp061GT++K3XqlHc5MmPyVkREBKtWrSI+Pp7OnTszfvx4Bg0aRKNGjVi0aFGGutu3b6dkyZKULl2aSy+9lBUrVnDZZZflar/pL9E8+5r+EiVKpD5v1aoVW7du5eDBg3zxxRcMGzYMAI/Hw5IlSwgPD8/2vaXf9vDhw7nuuuuYOXMmO3bsoF27dpnuU1X5/PPPqV8/42Xuzz//PBUrVmT16tV4PJ4s930+ZxSVK1dm165dVKlSheTkZI4fP05kZOajX8+ZM4fLL7+cihUrppY1aNCAb7/9FoDNmzcze/bs1HUJCQlEROTPcEFF8qqn0qXD2Lz5MBdfXJJp025n7tx7LEmYQq148eKMHTuWN954g+TkZO655x5++uknvvvOuXn01KlTDBo0KLUZY+jQobz88sup36o9Hg+TJk06Z7sdO3Zk/Pjxqctnmp4qVqzIhg0b8Hg8zJw5M8u4RIRbb72VIUOG0LBhw9QP0U6dOvH222+n1lu1atU5r23YsCFbt6aN0nz8+HEqV64MwAcffJDlPjt37szbb7/tdNLiXDl15vWVKlUiKCiI//znP6SkpGT6+sWLF7Nq1apzHmcnCYCbbrqJDz/8EIAZM2bQvn37LO9zmDp1aoZmJ4ADBw4AzvEfMWIE/fr1S123efPmDE1v/lRkEsW8eVtJTEwGIDKyOLNm9WTjxofp0aOx3RRlioTmzZvTtGlTpk6dSkREBF9++SUjRoygfv36NGnShCuvvJKBAwcC0LRpU9566y169epFw4YNady4Mdu3bz9nm8OGDePo0aM0btyYyy67jAULFgAwcuRIunfvztVXX02lSpWyjatHjx58/PHHqc1OAGPHjmX58uU0bdqURo0aZZqkGjRowPHjx1O/3T/xxBM8/fTTNG/enOTk5Cz3N3z4cJKSkmjatCmXXnopw4cPB2DAgAF8+OGHXHbZZWzcuDHDWUhu9e3bl8OHD1OnTh1Gjx7NyJEjAdizZw9du3ZNrXfy5Enmz5/PbbfdluH1U6dOpV69ejRo0IBLLrmEPn36pK5bsGAB3bp1u+AYfSFnsmqgiK4quvzLt+DyR32qv2vXcQYNmssXX2zkxRevY9iwNn6O0BjHhg0baNiwodthFGpvvvkmpUqV4h//+IfboeSrxMRE2rZty08//URIyLk9CJn97YnIClWNzs3+Cu0ZRXKyh9Gjf6Vhw/F88cVGSpYsRvnyNvy3MYVJ//79CQsLczuMfLdz505GjhyZaZLwh0LZmb1kSQz9+n3N6tX7Abj99oaMGdOFypVLuxyZMSYvhYeH07t3b7fDyHd169albt26+ba/wEwUp+OyXLV0aQxXX/0uqlCjRlnGjbuBbt3q5WNwxqRRVesDM/nKH90JgZkoLs66ma1Fi8p07lyH5s0vZtiwNhQvnneTdxhzPsLDwzl8+LANNW7yjXrno8jusuLcCMzO7LV/QpkaAGzZcpjBg+cxenRn6tVzLq3zeJSgIPvHNO6yGe6MG7Ka4e5COrMD84yiWCkSE5MZOfInXnnlJxITUwgPD2HGjLsALEmYAiE0NDRPZxkzxi1+vepJRLqIyCYR2SoiT2WyPkxEPvWuXyoiNXzZ7vcLdtG06SSef34hiYkp9OnTjEmTuud1+MYYY/DjGYWIBAPjgY5ADLBMRGap6vp01foCR1W1joj0BF4Fepy7tTR/HinL9d2+BKBhwygmTepug/gZY4wf+fOMogWwVVW3q+ppYBpw81l1bgY+9D6fAXSQHHr9jsZHEB4ezMsvt2fVqn6WJIwxxs/81pktIncAXVT1H97l3sBVqjowXZ213jox3uVt3jqHztrWg8CD3sXGwFq/BB14ooBDOdYqGuxYpLFjkcaORZr6qloqNy8MiM5sVZ0CTAEQkeW57bkvbOxYpLFjkcaORRo7FmlE5NzJNXzkz6an3UDVdMtVvGWZ1hGREKAMcNiPMRljjDlP/kwUy4C6IlJTRIoBPYFZZ9WZBdznfX4H8IMG2o0dxhhTyPmt6UlVk0VkIDAPCAbeU9V1IvICztyts4B3gf+IyFbgCE4yyckUf8UcgOxYpLFjkcaORRo7FmlyfSwC7s5sY4wx+avQDjNujDEmb1iiMMYYk60Cmyj8NfxHIPLhWAwRkfUiskZEvheRQnsXYk7HIl2920VERaTQXhrpy7EQkbu8fxvrROST/I4xv/jwP1JNRBaIyO/e/5OumW0n0InIeyJywHuPWmbrRUTGeo/TGhG53KcNq2qBe+B0fm8DagHFgNVAo7PqDAAmeZ/3BD51O24Xj8V1QHHv8/5F+Vh465UCFgFLgGi343bx76Iu8DtQzrtcwe24XTwWU4D+3ueNgB1ux+2nY9EGuBxYm8X6rsAcQICWwFJftltQzyj8MvxHgMrxWKjqAlWN9y4uwblnpTDy5e8C4EWcccMK8/jevhyLB4DxqnoUQFUP5HOM+cWXY6HAmSkuywB78jG+fKOqi3CuIM3KzcBH6lgClBWRSjltt6AmisrArnTLMd6yTOuoajJwHIjMl+jyly/HIr2+ON8YCqMcj4X3VLqqqs7Oz8Bc4MvfRT2gnoj8LCJLRKRLvkWXv3w5Fs8DfxORGOAb4JH8Ca3AOd/PEyBAhvAwvhGRvwHRQFu3Y3GDiAQBo4H7XQ6loAjBaX5qh3OWuUhEmqjqMVejckcv4ANVfUNEWuHcv9VYVT1uBxYICuoZhQ3/kcaXY4GIXA88A9ykqon5FFt+y+lYlMIZNPJHEdmB0wY7q5B2aPvydxEDzFLVJFX9E9iMkzgKG1+ORV/gMwBV/RUIxxkwsKjx6fPkbAU1UdjwH2lyPBYi0hyYjJMkCms7NORwLFT1uKpGqWoNVa2B019zk6rmejC0AsyX/5EvcM4mEJEonKao7fkZZD7x5VjsBDoAiEhDnERxMF+jLBhmAfd6r35qdmRkqAAABMxJREFUCRxX1b05vahANj2p/4b/CDg+HovXgZLAdG9//k5Vvcm1oP3Ex2NRJPh4LOYBnURkPZACDFXVQnfW7eOxeBx4R0QG43Rs318Yv1iKyFScLwdR3v6Y54BQAFWdhNM/0xXYCsQDfXzabiE8VsYYY/JQQW16MsYYU0BYojDGGJMtSxTGGGOyZYnCGGNMtixRGGOMyZYlClMgiUiKiKxK96iRTd24PNjfByLyp3dfK713757vNv4tIo28z/951rpfLjRG73bOHJe1IvKViJTNoX6zwjpSqsk/dnmsKZBEJE5VS+Z13Wy28QHwtarOEJFOwChVbXoB27vgmHLaroh8CGxW1ZeyqX8/zgi6A/M6FlN02BmFCQgiUtI718ZKEflDRM4ZNVZEKonIonTfuK/1lncSkV+9r50uIjl9gC8C6nhfO8S7rbUi8pi3rISIzBaR1d7yHt7yH0UkWkRGAhHeOP7rXRfn/TlNRLqli/kDEblDRIJF5HURWeadJ+AhHw7Lr3gHdBORFt73+P/tnU+oVVUUxn8f9fx3wdfAEBoEDdIQCsNmURZFSUEkGo8oQhCCCJtoNEgKRIyKAsNRiigUEmU2K7Xw4aOol/hez+zfpGnWoEHmCwSXg7UOnex4uo30wfeDzd373rXvXpsLZ5299z3fmpL0haTl9ZTyNmCsfBkr3/dKmizbLvVdY/7JldZPd3HpKuSTxNNVDpEqAovrsyXkk6XNivhsvW4GXqz6NaT20xLywj+o918AXuoYbx+wvuqPAV8Bq4BTwIB88v00cDuwDtjd6jtar+NU/ovGp5ZN4+NaYH/V55FKnguBp4Gt9f584ARwU4efZ1vzex9YU+3FwLVVvx84WPUNwK5W/x3Ak1W/jtR/Glzp39vl6i5XpYSHMcBsRKxsGpJGgB2S7gYukHfSS4FfWn2+BvaW7UcRMS1pNZmo5vOSN5lH3ol38bqkraQG0EZSG+hQRPxZPnwI3AV8Arwh6VVyu2rif8zrY2CnpPnAGuB4RMzWdtdtktaX3Sgp4PfzJf0XSpqu+X8PHG3Z75d0MylRMXKZ8R8AHpG0pdoLgBvru4zpxIHCzBWeAK4HVkXEeaU67IK2QUQcr0DyMLBP0pvA78DRiHh8iDGej4gPmoak+7qMIuInZd6Lh4Dtkj6LiG3DTCIi/pI0DjwIjJFJdiAzjm2KiMP/8RWzEbFS0iJS2+hZ4C0yWdOxiFhbB//jl+kvYF1E/DiMv8aAzyjM3GEU+LWCxL3Av/KCK3OFn4mI3cAeMiXkl8Cdkpozh4GkZUOOOQE8KmmRpAG5bTQh6QbgXES8QwoyduUdPl8rmy7eI8XYmtUJ5EX/maaPpGU1ZieRGQ2fAzbrb5n9Ri56Q8v0D3ILruEwsEm1vFIqDxvTiwOFmSu8C9wh6RTwFPBDh809wDeSpsi79Z0R8Rt54TwgaYbcdrplmAEj4iR5djFJnlnsiYgp4FZgsraAXga2d3R/G5hpDrMv4QiZXOrTyNSdkIHtO+CkpG9J2fjeFX/5MkMm5XkNeKXm3u53DFjRHGaTK4+R8u10tY3pxX+PNcYY04tXFMYYY3pxoDDGGNOLA4UxxpheHCiMMcb04kBhjDGmFwcKY4wxvThQGGOM6eUivoFQnQR5mCEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# get the predicted probabilities\n",
        "predicted_probs = kobert_predict(model, test_dataloader)\n",
        "\n",
        "# get the true labels\n",
        "y_true = []\n",
        "for _, _, _, label in test_dataloader:\n",
        "    y_true.extend(label.tolist())\n",
        "\n",
        "# calculate the fpr, tpr and thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_true, predicted_probs[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Bert Classifier ROC AUC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4MpLaqpZuJE"
      },
      "outputs": [],
      "source": [
        "def kobert_predict(model, data):\n",
        "    \"\"\"Perform a forward pass on the trained KoBERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_cls_embeddings = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(data):\n",
        "        # Load batch to GPU\n",
        "        token_ids = token_ids.long().cuda()\n",
        "        segment_ids = segment_ids.long().cuda()\n",
        "        valid_length = valid_length.cuda()\n",
        "        label = label.long().cuda()\n",
        "\n",
        "        # Compute  cls_embeddings\n",
        "        with torch.no_grad():\n",
        "            encoded_layers = model(token_ids, valid_length, segment_ids)\n",
        "            cls_embeddings = encoded_layers[-1][:, 0, :]\n",
        "            all_cls_embeddings.append(cls_embeddings)\n",
        "\n",
        "    cls_embeddings = torch.cat(all_cls_embeddings, dim=0)\n",
        "    cls_embeddings_matrix = cls_embeddings.detach().cpu().numpy()\n",
        "\n",
        "    return  cls_embeddings_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.matutils import corpus2dense\n",
        "\n",
        "# Create separate datasets for each label\n",
        "data_test_0 = [data for data in data_list if data[1] == 0]\n",
        "data_test_1 = [data for data in data_list if data[1] == 1]\n",
        "\n",
        "# Create dataloaders for each dataset\n",
        "dataloader_0 = torch.utils.data.DataLoader(BERTDataset(data_test_0, 0, 1, tok, max_len, True, False), batch_size=batch_size, num_workers=5)\n",
        "dataloader_1 = torch.utils.data.DataLoader(BERTDataset(data_test_1, 0, 1, tok, max_len, True, False), batch_size=batch_size, num_workers=5)\n",
        "\n",
        "low_cls_embeddings = kobert_predict(model, dataloader_0)\n",
        "\n",
        "high_cls_embeddings = kobert_predict(model, dataloader_1)\n"
      ],
      "metadata": {
        "id": "npW_P_3DwcdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save and compress.\n",
        "with open('low_cls_embeddings.pickle', 'wb') as f:\n",
        "    pickle.dump(low_cls_embeddings, f)\n",
        "\n",
        "with open('high_cls_embeddings.pickle', 'wb') as f:\n",
        "    pickle.dump(high_cls_embeddings, f)"
      ],
      "metadata": {
        "id": "coQ6Jply2hT0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}